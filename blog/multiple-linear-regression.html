<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multiple Linear Regression in R and Python | My Portfolio</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../blog-styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/r.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/python.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
<body>
    <header>
        <nav>
<!--             <div class="logo">
                <a href="../index.html">My Portfolio</a>
            </div> -->
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../blog.html" class="active">Blog</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main class="blog-post">
        <article>
            <header class="post-header">
                <h1>Multiple Linear Regression: Implementation in R and Python</h1>
                <div class="post-meta">
                    <time datetime="2025-03-27">March 27, 2025</time>
                    <span class="categories">
                        <a href="#">Data Science</a>
                        <a href="#">Statistics</a>
                        <a href="#">Programming</a>
                    </span>
                </div>
            </header>

            <div class="post-content">
                <h2>Introduction to Multiple Linear Regression</h2>
                <p>
                    Multiple linear regression is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. It's an extension of simple linear regression and is used when we want to predict the value of a variable based on the value of two or more other variables.
                </p>

                <p>
                    The multiple linear regression model can be represented as:
                </p>

                <div class="equation">
                    Y = β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ + ε
                </div>

                <p>
                    Where:
                </p>
                <ul>
                    <li>Y is the dependent variable</li>
                    <li>X₁, X₂, ..., Xₚ are the independent variables</li>
                    <li>β₀ is the y-intercept (constant term)</li>
                    <li>β₁, β₂, ..., βₚ are the coefficients for each independent variable</li>
                    <li>ε is the error term</li>
                </ul>

                <h2>Implementation in R</h2>
                <p>
                    R is a powerful language for statistical computing and graphics. Let's see how to implement multiple linear regression in R using a sample dataset.
                </p>

                <pre><code class="language-r">
# Load required libraries
library(ggplot2)

# Create a sample dataset
set.seed(123)
n <- 100
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
y <- 2 + 3*x1 - 0.5*x2 + 1.5*x3 + rnorm(n)
data <- data.frame(y=y, x1=x1, x2=x2, x3=x3)

# View the first few rows of the dataset
head(data)

# Fit the multiple linear regression model
model <- lm(y ~ x1 + x2 + x3, data=data)

# Display the summary of the model
summary(model)

# Visualize the results
par(mfrow=c(2,2))
plot(model)

# Predict using the model
new_data <- data.frame(x1=c(0.5, 1), x2=c(-0.5, 0), x3=c(1, 0.5))
predictions <- predict(model, newdata=new_data)
print(predictions)
                </code></pre>

                <p>
                    The output of the summary function provides important information about the model:
                </p>
                <ul>
                    <li>Coefficients: The estimated values of β₀, β₁, β₂, and β₃</li>
                    <li>Standard errors: The standard errors of the coefficient estimates</li>
                    <li>t-values and p-values: Used to test the significance of each coefficient</li>
                    <li>R-squared: The proportion of variance in the dependent variable explained by the independent variables</li>
                    <li>F-statistic: Tests the overall significance of the regression model</li>
                </ul>

                <h2>Implementation in Python</h2>
                <p>
                    Python, with libraries like scikit-learn and statsmodels, offers powerful tools for implementing multiple linear regression. Let's see how to do it:
                </p>

                <pre><code class="language-python">
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm

# Create a sample dataset
np.random.seed(123)
n = 100
x1 = np.random.normal(0, 1, n)
x2 = np.random.normal(0, 1, n)
x3 = np.random.normal(0, 1, n)
y = 2 + 3*x1 - 0.5*x2 + 1.5*x3 + np.random.normal(0, 1, n)

# Create a DataFrame
data = pd.DataFrame({
    'y': y,
    'x1': x1,
    'x2': x2,
    'x3': x3
})

# Display the first few rows
print(data.head())

# Split the data into training and testing sets
X = data[['x1', 'x2', 'x3']]
y = data['y']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Using scikit-learn
model_sklearn = LinearRegression()
model_sklearn.fit(X_train, y_train)

# Print the coefficients
print("Intercept:", model_sklearn.intercept_)
print("Coefficients:", model_sklearn.coef_)

# Make predictions
y_pred = model_sklearn.predict(X_test)

# Evaluate the model
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))

# Using statsmodels for more detailed statistics
X_with_const = sm.add_constant(X)
model_statsmodels = sm.OLS(y, X_with_const).fit()
print(model_statsmodels.summary())

# Visualize the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

# Residual plot
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='k', linestyle='--')
plt.xlabel('Predicted')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()
                </code></pre>

                <h2>Comparing R and Python for Multiple Linear Regression</h2>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Feature</th>
                            <th>R</th>
                            <th>Python</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Syntax</td>
                            <td>Simple and concise with the <code>lm()</code> function</td>
                            <td>More verbose, requires multiple libraries</td>
                        </tr>
                        <tr>
                            <td>Statistical Output</td>
                            <td>Comprehensive by default</td>
                            <td>Requires statsmodels for detailed statistics</td>
                        </tr>
                        <tr>
                            <td>Visualization</td>
                            <td>Built-in diagnostic plots</td>
                            <td>More customizable with matplotlib/seaborn</td>
                        </tr>
                        <tr>
                            <td>Integration</td>
                            <td>Better for statistical analysis only</td>
                            <td>Better for integrating with other data science tasks</td>
                        </tr>
                        <tr>
                            <td>Learning Curve</td>
                            <td>Steeper for general programming</td>
                            <td>Gentler for those with programming background</td>
                        </tr>
                    </tbody>
                </table>

                <h2>Assumptions of Multiple Linear Regression</h2>
                <p>
                    For multiple linear regression to be valid, several assumptions must be met:
                </p>
                <ol>
                    <li><strong>Linearity:</strong> The relationship between the independent and dependent variables should be linear.</li>
                    <li><strong>Independence:</strong> The observations should be independent of each other.</li>
                    <li><strong>Homoscedasticity:</strong> The residuals should have constant variance at every level of the independent variables.</li>
                    <li><strong>Normality:</strong> The residuals should be normally distributed.</li>
                    <li><strong>No multicollinearity:</strong> The independent variables should not be highly correlated with each other.</li>
                </ol>

                <h2>Conclusion</h2>
                <p>
                    Multiple linear regression is a powerful technique for predicting a continuous dependent variable based on multiple independent variables. Both R and Python offer robust tools for implementing and analyzing multiple linear regression models, each with its own strengths and weaknesses.
                </p>
                <p>
                    R excels in statistical analysis with its concise syntax and comprehensive output, while Python offers better integration with other data science tasks and more customizable visualizations. The choice between them depends on your specific needs and preferences.
                </p>
                <p>
                    Whether you're using R or Python, understanding the underlying assumptions and interpreting the results correctly is crucial for making valid inferences from your multiple linear regression models.
                </p>
            </div>
        </article>
    </main>

<div class="post-navigation">
        <div class="prev-post">
          <a href="#">&larr; Previous Post</a>
        </div>
        <div class="next-post">
          <a href="#">Next Post &rarr;</a>
        </div>
      </div>
    </div>
  </div>
    
    <footer>
        <div class="footer-content">
            <p>&copy; 2025 My Portfolio. All rights reserved.</p>
            <div class="social-links">
                <a href="https://github.com/MHMNP2021" target="_blank">GitHub</a>
                <a href="#" target="_blank">LinkedIn</a>
                <a href="#" target="_blank">Twitter</a>
            </div>
        </div>
    </footer>

    <script src="../script.js"></script>
</body>
</html>

